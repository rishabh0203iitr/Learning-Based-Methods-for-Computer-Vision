{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa489a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# helper function for image IO\n",
    "def load_image(path):\n",
    "  # load an image into RGB format\n",
    "  img = cv2.imread(path)\n",
    "  img = img[:, :, ::-1]  # BGR -> RGB\n",
    "  return img\n",
    "\n",
    "def save_image(path, img):\n",
    "  # save an RGB image into a file\n",
    "  img = img.copy()[:,:,::-1]\n",
    "  return cv2.imwrite(path, img)\n",
    "\n",
    "def resize_image(img, new_size, interpolation):\n",
    "    # resize an image into new_size (w * h) using specified interpolation\n",
    "    # opencv has a weird rounding issue & this is a hacky fix\n",
    "    # ref: https://github.com/opencv/opencv/issues/9096\n",
    "    mapping_dict = {cv2.INTER_NEAREST: cv2.INTER_NEAREST_EXACT}\n",
    "    if interpolation in mapping_dict:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            new_size,\n",
    "            interpolation=mapping_dict[interpolation]\n",
    "        )\n",
    "    else:\n",
    "        img = cv2.resize(\n",
    "            img,\n",
    "            new_size,\n",
    "            interpolation=interpolation\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple dataset\n",
    "class SimpleDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset using PyTorch dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, root_folder, file_ext, transforms=None):\n",
    "        # root folder, split\n",
    "        self.root_folder = root_folder\n",
    "        self.transforms = transforms\n",
    "        self.file_ext = file_ext\n",
    "\n",
    "        # list all files\n",
    "        file_list = glob.glob(os.path.join(root_folder, '*.{:s}'.format(file_ext)))\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load img and label (from file name)\n",
    "        filename = self.file_list[index]\n",
    "        img = load_image(filename).astype(np.float32) / 255.0\n",
    "        label = 1 if \"cat\" in os.path.basename(filename) else 0\n",
    "        # apply data augmentation\n",
    "        if self.transforms is not None:\n",
    "            img  = self.transforms(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple data augmentation\n",
    "class Compose(object):\n",
    "    \"\"\"\n",
    "    Composes several transforms together.\n",
    "    Args:\n",
    "      transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "      >>> Compose([\n",
    "      >>>     Scale(320),\n",
    "      >>>     RandomSizedCrop(224),\n",
    "      >>> ])\n",
    "    \"\"\"\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = \"\"\n",
    "        for t in self.transforms:\n",
    "            repr_str += t.__repr__() + '\\n'\n",
    "        return repr_str\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``numpy.ndarray`` image to tensor.\n",
    "    Converts a numpy.ndarray (H x W x C) image in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    def __call__(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        # convert image to tensor\n",
    "        assert (img.ndim > 1) and (img.ndim <= 3)\n",
    "        if img.ndim == 2:\n",
    "            img = img[:, :, None]\n",
    "            tensor_img = torch.from_numpy(\n",
    "                np.ascontiguousarray(img.transpose((2, 0, 1)))\n",
    "            )\n",
    "        if img.ndim == 3:\n",
    "            tensor_img = torch.from_numpy(\n",
    "                np.ascontiguousarray(img.transpose((2, 0, 1)))\n",
    "            )\n",
    "        # backward compatibility\n",
    "        if isinstance(tensor_img, torch.ByteTensor):\n",
    "            return tensor_img.float().div(255.0)\n",
    "        else:\n",
    "            return tensor_img\n",
    "\n",
    "class Resize(object):\n",
    "    \"\"\"\n",
    "    Resize an input image into a fixed resolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        assert (\n",
    "            isinstance(size, int)\n",
    "            or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "           )\n",
    "        if isinstance(size, int):\n",
    "            self.size = (size, size)\n",
    "        else:\n",
    "            self.size = size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        img = resize_image(img, self.size, cv2.INTER_LINEAR)\n",
    "        return img\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(); plt.axis('off'); plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cec0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image IO using PyTorch dataloader\n",
    "# set up the transforms (make sure you convert numpy array to pytorch tensor)\n",
    "transforms = []\n",
    "transforms.append(Resize(64))\n",
    "transforms.append(ToTensor())\n",
    "comp_transforms = Compose(transforms)\n",
    "\n",
    "# let us try a toy dataset\n",
    "train_batch_size, test_batch_size = 16, 4\n",
    "train_dataset = SimpleDataset('./data/mini_train', file_ext='jpg', transforms=comp_transforms)\n",
    "val_dataset = SimpleDataset('./data/mini_val', file_ext='jpg', transforms=comp_transforms)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_data_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "nrow = train_batch_size // 2\n",
    "imshow(torchvision.utils.make_grid(images, nrow=nrow))\n",
    "classes = (\"dog\", \"cat\")\n",
    "# print labels\n",
    "output = ''\n",
    "for i, j in enumerate(range(train_batch_size), 1):\n",
    "    output += f'{classes[labels[j]]:5s}' + ['\\t', '\\n'][i % nrow == 0]\n",
    "print(output)\n",
    "del dataiter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec4dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple neural network modified from PyTorch tutorial\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c528cdf-67d6-4b3e-a19c-cd464b51b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(6):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a35a3-b35c-4659-846c-a6b9f6bffe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us look at network outputs using the validation set\n",
    "dataiter = iter(val_data_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images, nrow=test_batch_size))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "# prediction using the trained network\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted  : ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(test_batch_size)))\n",
    "del dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d7901-b835-49c1-b7af-e32a60196dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on the validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in val_data_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the validation set: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba748fd-97a6-45f4-b37b-1a9eeb718cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
