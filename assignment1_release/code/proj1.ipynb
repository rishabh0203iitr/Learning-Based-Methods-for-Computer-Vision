{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# BMI / CS 771: Homework Assignment 1\n",
    "\n",
    "This project will use Jupyter Notebook in combination with Python scripts, offering a convenient way for you to quickly and easily interact with the code. A notebook contains many blocks of code, each of which can be run independently. You can run a cell with ctrl+enter or shift+enter (to move to the next cell).\n",
    "\n",
    "If there are any notes you wish to leave for the teaching team, you may leave them here.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils import load_image, save_image\n",
    "from student_code import Compose, Scale, RandomHorizontalFlip, RandomColor, RandomRotate, RandomSizedCrop\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "image1 = load_image('../data/dog.bmp')\n",
    "image2 = load_image('../data/bird.bmp')\n",
    "image3 = load_image('../data/cat.bmp')\n",
    "image4 = load_image('../data/plane.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.axis('off'); plt.imshow(image1);\n",
    "plt.figure(figsize=(3,3)); plt.axis('off'); plt.imshow(image2);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list and add transforms one by one\n",
    "transforms = []\n",
    "transforms.append(Scale(320))\n",
    "transforms.append(RandomHorizontalFlip())\n",
    "transforms.append(RandomColor(0.15))\n",
    "transforms.append(RandomRotate(30))\n",
    "transforms.append(RandomSizedCrop(224))\n",
    "comp_transforms = Compose(transforms)\n",
    "print(comp_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Transforms to Images\n",
    "All functions you need to implement in this project can be found in student_code.py. You will need to fill in the missing code pieces in the Scale, RandomRotate and RandomColor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image1 = comp_transforms(image1)\n",
    "\n",
    "# let's take a look at the results!\n",
    "plt.figure(figsize=(4,4)); plt.axis('off'); plt.imshow(image1);\n",
    "plt.figure(figsize=(4,4)); plt.axis('off'); plt.imshow(transformed_image1);\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create More Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vis_img_list = []\n",
    "for img in [image1, image2, image3, image4]:\n",
    "    img_list = []\n",
    "    for idx in range(10):\n",
    "        img_list.append(comp_transforms(img))\n",
    "    vis_img = np.concatenate(img_list, axis=1)\n",
    "    vis_img_list.append(vis_img)\n",
    "\n",
    "for vis_img in vis_img_list:\n",
    "    plt.figure(figsize=(16,16)); plt.axis('off'); plt.imshow(vis_img);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_idx, vis_img in zip(range(len(vis_img_list)), vis_img_list):\n",
    "    save_image('../results/outputs_{:d}.jpg'.format(file_idx), vis_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from student_code import ToTensor, SimpleDataset, CenterCrop, Resize, Net\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# now we will do some real training on cats and dogs\n",
    "\n",
    "# set up the transforms (you can play around with the combination here)\n",
    "train_transforms = []\n",
    "train_transforms.append(Scale(72))\n",
    "train_transforms.append(RandomHorizontalFlip())\n",
    "train_transforms.append(RandomSizedCrop(64, area_range=(0.64, 1.0)))\n",
    "train_transforms.append(ToTensor())\n",
    "train_transforms = Compose(train_transforms)\n",
    "\n",
    "test_transforms = []\n",
    "test_transforms.append(Scale(72))\n",
    "test_transforms.append(CenterCrop(64))\n",
    "test_transforms.append(ToTensor())\n",
    "test_transforms = Compose(test_transforms)\n",
    "print(\"Image transforms used for training\")\n",
    "print(train_transforms)\n",
    "print(\"Image transforms used for validation:\")\n",
    "print(test_transforms)\n",
    "\n",
    "# let us try a toy dataset\n",
    "batch_size = 16\n",
    "train_dataset = SimpleDataset('../data/mini_train', file_ext='jpg', transforms=train_transforms)\n",
    "val_dataset = SimpleDataset('../data/mini_val', file_ext='jpg', transforms=test_transforms)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_data_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "nrow = batch_size // 2\n",
    "vis_img = torchvision.utils.make_grid(images, nrow=nrow).numpy()\n",
    "plt.figure(); plt.axis('off'); plt.imshow(np.transpose(vis_img, (1, 2, 0)))\n",
    "plt.show()\n",
    "classes = (\"dog\", \"cat\")\n",
    "# print labels\n",
    "output = ''\n",
    "for i, j in enumerate(range(batch_size), 1):\n",
    "    output += f'{classes[labels[j]]:5s}' + ['\\t', '\\n'][i % nrow == 0]\n",
    "print(output)\n",
    "del dataiter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network / loss function for training\n",
    "net = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on the validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_data_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the validation set: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
